"""
Conversation Service
Business logic cho chat conversations
"""
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, desc, func
from typing import Optional, List, Dict, Tuple
from uuid import UUID
from datetime import datetime

from app.models import User, Conversation, Message
from app.schemas import ChatRequest, ChatResponse, MessageResponse
from app.services import openRouterService
from app.modules.conversation.prompts import getSystemPrompt, formatMessagesForAI
from app.modules.conversation.emotion_analyzer import analyzeEmotion
from app.modules.conversation.suggestion_engine import (
    shouldSuggestActivity,
    getSuggestedActivity,
    generateSuggestionMessage
)
from app.utils.logger import logger
from app.utils.exceptions import NotFoundException
from app.modules.conversation.simple_responder import (
    isSimplePattern,
    isSimpleGreeting,  # Keep for backward compatibility
    getSimpleResponse
)

from app.modules.conversation.prompts import buildCombinedPrompt
import json

# ============================================================
# GLOBAL CACHES (persist across requests)
# ============================================================
_USER_CACHE = {}
_CONVERSATION_CACHE = {}
_CACHE_TTL = 3600  # 1 hour


class ConversationService:
    """
    Service x·ª≠ l√Ω conversation logic
    
    Gi·∫£i th√≠ch:
    - Service layer = business logic
    - T√°ch bi·ªát v·ªõi endpoints (controller)
    - Reusable, testable
    
    Responsibilities:
    1. Qu·∫£n l√Ω users, conversations, messages
    2. Emotion analysis
    3. AI response generation
    4. Activity suggestions
    5. Database operations
    """
    
    def __init__(self, db: AsyncSession):
        self.db = db
    
    
    async def getOrCreateUser(self, userId: UUID) -> User:
        """
        Get or create user - OPTIMIZED
        
        Optimization:
        - Single query instead of SELECT + INSERT
        - Use ON CONFLICT for upsert
        """
        cache_key = str(userId)
        
        # Check cache
        if cache_key in _USER_CACHE:
            user, cached_at = _USER_CACHE[cache_key]
            age = (datetime.utcnow() - cached_at).total_seconds()
            
            if age < _CACHE_TTL:
                #logger.info(f"‚ö° User cache HIT (age: {age:.0f}s)")
                return user
            else:
                logger.info(f"‚è∞ User cache EXPIRED (age: {age:.0f}s)")
        
        # Cache miss or expired - query DB
        logger.info(f"üíæ User cache MISS - querying DB")

        from sqlalchemy.dialects.postgresql import insert
    
        stmt = insert(User).values(
            id=userId,
            display_name="User",
            language="vi",
            timezone="Asia/Ho_Chi_Minh",
            memory_enabled=True
        ).on_conflict_do_update(
            index_elements=['id'],
            set_={'updated_at': datetime.utcnow()}
        ).returning(User)
        
        result = await self.db.execute(stmt)
        user = result.scalar_one()
        await self.db.flush()  
        
        # Update cache
        _USER_CACHE[cache_key] = (user, datetime.utcnow())
        return user
    
    
    async def getOrCreateConversation(
        self,
        userId: UUID,
        conversationId: Optional[UUID] = None
    ) -> Conversation:
        """
        L·∫•y conversation hi·ªán t·∫°i ho·∫∑c t·∫°o m·ªõi - OPTIMIZED with caching
        
        Args:
            userId: User ID
            conversationId: Conversation ID (None = t·∫°o m·ªõi)
        
        Returns:
            Conversation object
        
        Optimization:
        - Cache conversations in memory
        - Skip DB query if cached and fresh
        """
        if conversationId:
            cache_key = str(conversationId)
            
            # Check cache
            if cache_key in _CONVERSATION_CACHE:
                conversation, cached_at = _CONVERSATION_CACHE[cache_key]
                age = (datetime.utcnow() - cached_at).total_seconds()
                
                if age < _CACHE_TTL:
                    #logger.info(f"‚ö° Conversation cache HIT (age: {age:.0f}s)")
                    return conversation
                else:
                    logger.info(f"‚è∞ Conversation cache EXPIRED (age: {age:.0f}s)")
            
            # Cache miss - query DB
            logger.info(f"üíæ Conversation cache MISS - querying DB")
            stmt = select(Conversation).where(Conversation.id == conversationId)
            result = await self.db.execute(stmt)
            conversation = result.scalar_one_or_none()
            
            if conversation:
                # Update cache
                _CONVERSATION_CACHE[cache_key] = (conversation, datetime.utcnow())
                logger.info(f"üìÇ Loaded conversation: {conversationId}")
                return conversation
        
        # T·∫°o m·ªõi
        conversation = Conversation(
            user_id=userId,
            title="New Chat",
            status='active',
            emotion_progression=[] 
        )
        self.db.add(conversation)
        await self.db.flush() 
        
        # Cache new conversation
        cache_key = str(conversation.id)
        _CONVERSATION_CACHE[cache_key] = (conversation, datetime.utcnow())
        
        logger.info(f"üìù New conversation: {conversation.id}")
        return conversation
    
    
    async def getConversationContext(
        self,
        conversationId: UUID,
        limit: int = 20
    ) -> List[Message]:
        """
        Load N messages g·∫ßn nh·∫•t ƒë·ªÉ l√†m context
        
        Args:
            conversationId: Conversation ID
            limit: S·ªë messages t·ªëi ƒëa (default: 20)
        
        Returns:
            List[Message] ordered t·ª´ c≈© ‚Üí m·ªõi
        
        Gi·∫£i th√≠ch:
        - AI c·∫ßn context ƒë·ªÉ hi·ªÉu conversation
        - Limit 20 ƒë·ªÉ tr√°nh v∆∞·ª£t token limit
        - Order DESC ƒë·ªÉ l·∫•y messages m·ªõi nh·∫•t
        - Reverse ƒë·ªÉ c√≥ th·ª© t·ª± ƒë√∫ng (c≈© ‚Üí m·ªõi)
        """
        stmt = select(Message).where(
            Message.conversation_id == conversationId
        ).order_by(
            desc(Message.sequence_number)
        ).limit(limit)
        
        result = await self.db.execute(stmt)
        messages = result.scalars().all()
        
        return list(reversed(messages))
    
    
    async def getNextSequenceNumber(self, conversationId: UUID) -> int:
        """
        L·∫•y sequence_number ti·∫øp theo
        
        Gi·∫£i th√≠ch:
        - sequence_number = th·ª© t·ª± message (1, 2, 3, ...)
        - Query max(sequence_number) + 1
        - Return 1 n·∫øu ch∆∞a c√≥ message n√†o
        """
        stmt = select(func.max(Message.sequence_number)).where(
            Message.conversation_id == conversationId
        )
        result = await self.db.execute(stmt)
        maxSeq = result.scalar()
        
        return (maxSeq + 1) if maxSeq else 1
    
    
    async def saveMessage(
        self,
        conversationId: UUID,
        userId: UUID,
        role: str,
        content: str,
        sequenceNumber: int,
        emotionData: Optional[Dict] = None,
        metadata: Optional[Dict] = None
    ) -> Message:
        """
        L∆∞u message v√†o database
        
        Args:
            conversationId: Conversation ID
            userId: User ID
            role: 'user' | 'assistant' | 'system'
            content: Message content
            sequenceNumber: Sequence number
            emotionData: {emotion_state, energy_level, urgency_level, detected_themes}
            metadata: {model_used, prompt_tokens, completion_tokens, response_time_ms}
        
        Returns:
            Message object ƒë√£ save
        
        Flow:
        1. Create Message object
        2. Add emotion data (cho user messages)
        3. Add AI metadata (cho assistant messages)
        4. Save to DB
        5. Flush (get ID)
        
        ‚ö†Ô∏è NOTE: message_count t·ª± ƒë·ªông tƒÉng b·ªüi trigger trong DB
        """
        message = Message(
            conversation_id=conversationId,
            user_id=userId,
            role=role,
            content=content,
            content_type="text",
            sequence_number=sequenceNumber,
            # Emotion data (for user messages)
            emotion_state=emotionData.get("emotion_state") if emotionData else None,
            energy_level=emotionData.get("energy_level") if emotionData else None,
            urgency_level=emotionData.get("urgency_level") if emotionData else None,
            detected_themes=emotionData.get("detected_themes", []) if emotionData else [],
            # AI metadata (for assistant messages)
            model_used=metadata.get("model") if metadata else None,
            prompt_tokens=metadata.get("promptTokens") if metadata else None,
            completion_tokens=metadata.get("completionTokens") if metadata else None,
            response_time_ms=metadata.get("responseTimeMs") if metadata else None
    )
        
        self.db.add(message)
        await self.db.flush()
        
        return message
    
    
    async def updateEmotionProgression(
        self,
        conversationId: UUID,
        emotionState: str,
        energyLevel: int
    ):
        """
        Update emotion_progression trong conversation
        
        Args:
            conversationId: Conversation ID
            emotionState: Current emotion
            energyLevel: Current energy level
        
        Gi·∫£i th√≠ch:
        - emotion_progression = JSONB array tracking emotions over time
        - Format: [{"timestamp": "...", "emotion": "anxious", "energy": 3}, ...]
        - Append new snapshot m·ªói l·∫ßn chat
        - Update dominant_emotion = emotion xu·∫•t hi·ªán nhi·ªÅu nh·∫•t
        
        Flow:
        1. Load conversation
        2. Get current progression array
        3. Append new snapshot
        4. Update dominant_emotion (most common)
        """
        stmt = select(Conversation).where(Conversation.id == conversationId)
        result = await self.db.execute(stmt)
        conversation = result.scalar_one()
        
        # Get current progression
        progression = conversation.emotion_progression or []
        
        # Add new snapshot
        progression.append({
            "timestamp": datetime.utcnow().isoformat(),
            "emotion": emotionState,
            "energy": energyLevel
        })
        
        conversation.emotion_progression = progression
        
        # Update dominant_emotion
        emotions = [p["emotion"] for p in progression]
        from collections import Counter
        mostCommon = Counter(emotions).most_common(1)
        if mostCommon:
            conversation.dominant_emotion = mostCommon[0][0]
        
        # Invalidate cache (data changed)
        cache_key = str(conversationId)
        if cache_key in _CONVERSATION_CACHE:
            _CONVERSATION_CACHE[cache_key] = (conversation, datetime.utcnow())
    
    
    async def generateAIResponse(
        self,
        userMessage: str,
        contextMessages: List[Message],
        userContext: Optional[Dict],
        emotionState: Optional[str]
    ) -> Tuple[str, Dict]:
        """
        Generate AI response v·ªõi tone adjusted
        
        Args:
            userMessage: User message content
            contextMessages: Chat history (max 20)
            userContext: User info (language, patterns...)
            emotionState: Current emotion ƒë·ªÉ adjust tone
        
        Returns:
            Tuple[str, Dict]: (AI response content, metadata)
        
        Flow:
        1. Get system prompt (v·ªõi tone adjusted theo emotion)
        2. Format messages (system + history + new user message)
        3. Call OpenRouter API
        4. Return content + metadata
        """
        # System prompt with emotion-adjusted tone
        systemPrompt = getSystemPrompt(userContext, emotionState)
        
        # Format messages
        messages = formatMessagesForAI(contextMessages, systemPrompt)
        messages.append({"role": "user", "content": userMessage})
        
        logger.info(f"ü§ñ Generating AI response: {len(messages)} messages, emotion={emotionState}")
        
        # Call AI
        result = await openRouterService.chat(
            messages=messages,
            temperature=0.8,  
            maxTokens=800
        )
        
        metadata = {
            "model_used": result["model"],
            "prompt_tokens": result["promptTokens"],
            "completion_tokens": result["completionTokens"],
            "response_time_ms": result["responseTimeMs"]
        }
        
        return result["content"], metadata
    
    # Th√™m v√†o cu·ªëi class ConversationService (tr∆∞·ªõc method chat)

    async def shouldSendProactiveGreeting(self, conversationId: UUID) -> bool:
        """
        Ki·ªÉm tra xem c√≥ n√™n g·ª≠i proactive greeting kh√¥ng
        
        Returns:
            True n·∫øu l√† conversation m·ªõi (ch∆∞a c√≥ message)
        """
        stmt = select(func.count(Message.id)).where(
            Message.conversation_id == conversationId
        )
        result = await self.db.execute(stmt)
        messageCount = result.scalar()
        
        return messageCount == 0


    async def sendProactiveGreeting(self, conversationId: UUID, userId: UUID) -> Message:
        """
        G·ª≠i proactive greeting message khi user v√†o conversation m·ªõi
        
        Returns:
            Assistant message object
        """
        from app.modules.conversation.prompts import getProactiveGreeting
        
        greetingContent = getProactiveGreeting()
        
        # Save greeting message
        message = await self.saveMessage(
            conversationId=conversationId,
            userId=userId,
            role="assistant",
            content=greetingContent,
            sequenceNumber=1,
            metadata={
                "model": "proactive-greeting",
                "promptTokens": 0,
                "completionTokens": 0,
                "responseTimeMs": 0
            }
        )
        
        await self.db.commit()
        logger.info(f"‚úÖ Sent proactive greeting: {greetingContent}")
        
        return message

    async def chat(self, userId: UUID, request: ChatRequest) -> ChatResponse:
        """
        üöÄ OPTIMIZED CHAT FUNCTION
    
        OPTIMIZATION STRATEGY:
        1. Parallel AI calls (emotion + response) ‚Üí Save ~2.5s
        2. Detailed timing logs ‚Üí Visibility
        3. Fallback mechanism ‚Üí Reliability
            
            FLOW HO√ÄN CH·ªàNH:
            
            1. ‚úÖ Verify/Create user
            2. üìÇ Get/Create conversation
            3. üìö Load context (20 messages g·∫ßn nh·∫•t)
            4. üé≠ Analyze emotion t·ª´ user message
            5. üí¨ Save user message (v·ªõi emotion data)
            6. üìä Update emotion_progression
            7. ü§ñ Generate AI response (tone adjusted)
            8. üí° Suggest activity (n·∫øu c·∫ßn)
            9. üíæ Save AI message
            10. ‚úÖ Commit transaction
            11. üì§ Return response
            
            Gi·∫£i th√≠ch t·ª´ng b∆∞·ªõc:
            - Step 1-2: Setup conversation
            - Step 3: Load context cho AI
            - Step 4: Detect emotion ƒë·ªÉ adjust tone
            - Step 5: Save user message
            - Step 6: Track emotion over time
            - Step 7: Generate empathetic response
            - Step 8: Suggest activity n·∫øu user c·∫ßn
            - Step 9-10: Save v√† commit
            - Step 11: Return data cho frontend
        """
        import time
        from app.modules.conversation.emotion_analyzer import analyzeEmotionSimple
        import asyncio
        
        overall_start = time.time()
        
        logger.info("=" * 80)
        logger.info(f"üöÄ CHAT REQUEST STARTED")
        logger.info(f"üìç User ID: {userId}")
        logger.info(f"üí¨ Message: {request.message[:60]}{'...' if len(request.message) > 60 else ''}")
        logger.info(f"üïê Timestamp: {datetime.utcnow().isoformat()}")
        logger.info("=" * 80)
        

        # ============================================================
        # PHASE 1: SETUP (Fast sequential operations)
        # ============================================================
        
        phase1_start = time.time()
        
        # 1. ‚úÖ Verify/Create user
        step_start = time.time()
        user = await self.getOrCreateUser(userId)
        step_time = (time.time() - step_start) * 1000
        logger.info(f"‚è±Ô∏è  Step 1 (Get user): {step_time:.0f}ms")
        
        # 2. üìÇ Get/Create conversation
        step_start = time.time()
        conversation = await self.getOrCreateConversation(userId, request.conversationId)
        step_time = (time.time() - step_start) * 1000
        logger.info(f"‚è±Ô∏è  Step 2 (Get/Create conversation): {step_time:.0f}ms")
        
        # 3. üìö Load context (20 messages g·∫ßn nh·∫•t)
        step_start = time.time()
        contextMessages = []
        if request.includeContext:
            contextMessages = await self.getConversationContext(conversation.id, 20)
        contextUsed = len(contextMessages)
        step_time = (time.time() - step_start) * 1000
        logger.info(f"‚è±Ô∏è  Step 3 (Load context): {step_time:.0f}ms (messages: {contextUsed})")
        
        phase1_elapsed = (time.time() - phase1_start) * 1000
        logger.info(f"‚úÖ Phase 1 Complete: {phase1_elapsed:.0f}ms")
        
        # Prepare user context (needed for both fast and normal paths)
        userContext = {"language": user.language}
        
        # ============================================================
        # üöÄ FAST PATH: Simple Patterns (greetings, thanks, bye, yes/no)
        # ============================================================
        
        if isSimplePattern(request.message):
            logger.info("‚ö° FAST PATH: Simple pattern detected")
            
            # Use simple responder (instant)
            aiContent, metadata = getSimpleResponse(request.message)
            
            # Use fallback emotion
            from app.modules.conversation.emotion_analyzer import analyzeEmotionSimple
            emotionData = await analyzeEmotionSimple(request.message)
            emotionState = "neutral"
            energyLevel = 5
            
            logger.info("‚ö° Skipping AI calls (simple pattern - instant response)")
            
            # Jump to Phase 3 (save to DB)
            phase2_elapsed = 0
            
        else:
            # ============================================================
            # PHASE 2: AI RESPONSE (with rule-based emotion)
            # ============================================================
            logger.info("üîÑ PHASE 2: AI Response Generation...")
            phase2_start = time.time()

            try:
                # ‚ö° FAST: Rule-based emotion (1ms)
                from app.modules.conversation.emotion_analyzer import analyzeEmotionSimple
                emotionData = await analyzeEmotionSimple(request.message)
                emotionState = emotionData.get("emotion_state", "neutral")
                
                logger.info(f"‚ö° Emotion (rule-based): {emotionState}, energy={emotionData.get('energy_level')}")
                
                # ü§ñ AI Response with emotion context
                aiContent, metadata = await self.generateAIResponse(
                    userMessage=request.message,
                    contextMessages=contextMessages,
                    userContext=userContext,
                    emotionState=emotionState
                )

                phase2_elapsed = (time.time() - phase2_start) * 1000
            
                logger.info(f"‚úÖ Phase 2 Complete: {phase2_elapsed:.0f}ms (OPTIMIZED)")
                logger.info(f"   üí° Saved ~2s vs parallel AI approach")
            
            except Exception as e:
                logger.error(f"‚ùå AI response failed: {e}")
                raise

        emotionState = emotionData.get("emotion_state", "neutral")
        energyLevel = emotionData.get("energy_level", 5)
        
        logger.info(f"üé≠ Emotion Result: {emotionState.upper()}")
        logger.info(f"   Energy: {energyLevel}/10, Urgency: {emotionData.get('urgency_level', 'low')}")
        logger.info(f"   Themes: {', '.join(emotionData.get('detected_themes', []))}")
        logger.info(f"   Method: {emotionData.get('method', 'ai')}")
        
        # In method `chat`, Phase 3:

        # ============================================================
        # PHASE 3: BATCH DATABASE OPERATIONS
        # ============================================================

        logger.info("üíæ PHASE 3: Batch database operations...")
        phase3_start = time.time()

        # Prepare sequence number
        seqNum = await self.getNextSequenceNumber(conversation.id)

        # Create user message
        userMessage = Message(
            conversation_id=conversation.id,
            user_id=userId,
            role="user",
            content=request.message,
            sequence_number=seqNum,
            emotion_state=emotionData.get("emotion_state"),
            energy_level=emotionData.get("energy_level"),
            urgency_level=emotionData.get("urgency_level"),
            detected_themes=emotionData.get("detected_themes", [])
        )

        # Create AI message
        assistantMessage = Message(
            conversation_id=conversation.id,
            user_id=userId,
            role="assistant",
            content=aiContent,
            sequence_number=seqNum + 1,
            model_used=metadata.get("model"),
            prompt_tokens=metadata.get("promptTokens"),
            completion_tokens=metadata.get("completionTokens"),
            response_time_ms=metadata.get("responseTimeMs")
        )

        # Update emotion progression
        progression = conversation.emotion_progression or []
        progression.append({
            "timestamp": datetime.utcnow().isoformat(),
            "emotion": emotionState,
            "energy": energyLevel
        })
        conversation.emotion_progression = progression

        # Update dominant emotion
        from collections import Counter
        emotions = [p["emotion"] for p in progression if p.get("emotion")]
        if emotions:
            mostCommon = Counter(emotions).most_common(1)
            conversation.dominant_emotion = mostCommon[0][0]

        # Check suggestion
        suggestion = None
        if shouldSuggestActivity(emotionData, request.message):
            activity = getSuggestedActivity(emotionData)
            if activity:
                suggestion = activity
                suggestionMsg = generateSuggestionMessage(activity)
                assistantMessage.content += f"\n\n{suggestionMsg}"
                logger.info(f"üí° Suggested: {activity['activity_type']}")

        # üÜï Auto-generate title for new conversations (first USER message)
        # Count user messages in context (exclude current one being saved)
        user_message_count = sum(1 for msg in contextMessages if msg.role == "user")
        
        # If this is the first user message and title is still default
        if user_message_count == 0 and conversation.title == "New Chat":
            # Generate title from first user message (max 50 chars)
            title = request.message[:50].strip()
            if len(request.message) > 50:
                title += "..."
            
            # CRITICAL: Merge conversation into session
            conversation = await self.db.merge(conversation)
            conversation.title = title
            logger.info(f"üìù Auto-generated title: {title}")

        # ‚ö° ADD ALL AT ONCE
        self.db.add_all([userMessage, assistantMessage])

        # ‚ö° SINGLE COMMIT
        await self.db.commit()

        phase3_elapsed = (time.time() - phase3_start) * 1000
        logger.info(f"‚úÖ Phase 3 Complete: {phase3_elapsed:.0f}ms (BATCHED)")
        
        # ============================================================
        # FINAL SUMMARY
        # ============================================================
        
        total_elapsed = (time.time() - overall_start) * 1000
        
        logger.info("=" * 80)
        logger.info(f"‚úÖ CHAT REQUEST COMPLETED SUCCESSFULLY")
        logger.info(f"")
        logger.info(f"‚è±Ô∏è  TOTAL TIME: {total_elapsed:.0f}ms ({total_elapsed/1000:.2f}s)")
        logger.info(f"")
        logger.info(f"üìä PHASE BREAKDOWN:")
        logger.info(f"   Phase 1 (Setup):        {phase1_elapsed:>6.0f}ms ({phase1_elapsed/total_elapsed*100:>5.1f}%)")
        logger.info(f"   Phase 2 (AI Parallel):  {phase2_elapsed:>6.0f}ms ({phase2_elapsed/total_elapsed*100:>5.1f}%)")
        logger.info(f"   Phase 3 (Database):     {phase3_elapsed:>6.0f}ms ({phase3_elapsed/total_elapsed*100:>5.1f}%)")
        logger.info(f"")
        logger.info(f"üöÄ OPTIMIZATION IMPACT:")
        logger.info(f"   Estimated sequential time: ~{total_elapsed + 2500:.0f}ms")
        logger.info(f"   Parallel optimization saved: ~2500ms")
        logger.info(f"   Speed improvement: ~{(2500/(total_elapsed + 2500)*100):.0f}% faster")
        logger.info(f"")
        logger.info(f"üìà METRICS:")
        logger.info(f"   Tokens (AI): {metadata.get('completion_tokens', 0)} completion + {metadata.get('prompt_tokens', 0)} prompt")
        logger.info(f"   Context used: {contextUsed} messages")
        logger.info(f"   Conversation: {conversation.id}")
        logger.info("=" * 80)
        
        # ============================================================
        # RETURN RESPONSE
        # ============================================================
        # 11. üì§ Return response
        return ChatResponse(
            conversation_id=conversation.id,
            user_message=MessageResponse.model_validate(userMessage),
            assistant_message=MessageResponse.model_validate(assistantMessage),
            context_used=contextUsed,
            suggestion=suggestion
        )
    
    
    async def getConversationById(
        self,
        userId: UUID,
        conversationId: UUID
    ) -> Conversation:
        """
        L·∫•y conversation detail
        
        Flow:
        - Query conversation by id + user_id
        - Raise 404 n·∫øu kh√¥ng t√¨m th·∫•y
        - Messages auto-loaded b·ªüi relationship
        """
        stmt = select(Conversation).where(
            Conversation.id == conversationId,
            Conversation.user_id == userId
        )
        result = await self.db.execute(stmt)
        conversation = result.scalar_one_or_none()
        
        if not conversation:
            raise NotFoundException(f"Conversation {conversationId} not found")
        
        return conversation


    async def generateCombinedResponse(
        self,
        userMessage: str,
        contextMessages: List[Message]
    ) -> Tuple[Dict, str, Dict]:
        """
        üöÄ COMBINED: Ph√¢n t√≠ch emotion + Generate response trong 1 API call
        
        Args:
            userMessage: User message
            contextMessages: Context messages
        
        Returns:
            Tuple[emotionData, aiContent, metadata]
        
        Optimization:
        - 1 API call thay v√¨ 2
        - Gi·∫£m t·ª´ ~3s (parallel) ‚Üí ~2.5s (1 call)
        - Emotion v√† response consistent v·ªõi nhau
        """
        # Build context
        context = [
            {
                "role": msg.role,
                "content": msg.content
            }
            for msg in contextMessages
        ]
        
        # Build combined prompt
        messages = buildCombinedPrompt(userMessage, context)
        
        logger.info(f"ü§ñ Combined API call: {len(messages)} messages")
        
        # Call OpenRouter
        try:
            result = await openRouterService.chat(
                messages=messages,
                temperature=0.7,  # Balanced
                maxTokens=1000    # Enough for emotion + response
            )
            
            # Parse JSON response
            content = result["content"].strip()
            
            # Remove markdown code blocks if present
            if content.startswith("```"):
                lines = content.split("\n")
                content = "\n".join(lines[1:-1])  # Remove first and last line
                if content.startswith("json"):
                    content = content[4:]
                content = content.strip()
            
            # Fix double curly braces (AI sometimes returns {{ instead of {)
            content = content.replace("{{", "{").replace("}}", "}")
            
            data = json.loads(content)
            
            # Extract emotion data
            emotionData = data.get("emotion_analysis", {})
            emotionData["method"] = "ai_combined"
            
            # Extract response
            responseData = data.get("response", {})
            aiContent = responseData.get("content", "")
            
            # Build metadata
            metadata = {
                "model": result["model"],
                "promptTokens": result["promptTokens"],
                "completionTokens": result["completionTokens"],
                "responseTimeMs": result["responseTimeMs"],
                "tone": responseData.get("tone", "neutral")
            }
            
            logger.info(f"‚úÖ Combined response: emotion={emotionData.get('emotion_state')}, {len(aiContent)} chars")
            
            return emotionData, aiContent, metadata
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå Failed to parse JSON: {e}")
            logger.error(f"   Content: {content[:200]}")
            
            # Fallback: Use simple emotion + content as-is
            from app.modules.conversation.emotion_analyzer import analyzeEmotionSimple
            emotionData = await analyzeEmotionSimple(userMessage)
            
            metadata = {
                "model": result["model"],
                "promptTokens": result["promptTokens"],
                "completionTokens": result["completionTokens"],
                "responseTimeMs": result["responseTimeMs"]
            }
            
            return emotionData, content, metadata
    
    
    # ============================================================
    # CONVERSATION HISTORY METHODS
    # ============================================================
    
    async def listUserConversations(
        self,
        userId: UUID,
        limit: int = 20,
        offset: int = 0
    ) -> Tuple[List[Conversation], int]:
        """
        L·∫•y danh s√°ch conversations c·ªßa user v·ªõi pagination
        
        Args:
            userId: User ID
            limit: S·ªë conversations t·ªëi ƒëa (default: 20)
            offset: Offset cho pagination (default: 0)
        
        Returns:
            Tuple[List[Conversation], int]: (conversations, total_count)
        
        Flow:
            1. Query conversations c·ªßa user
            2. Order by started_at DESC (m·ªõi nh·∫•t tr∆∞·ªõc)
            3. Apply pagination (limit, offset)
            4. Return conversations + total count
        """
        # Count total conversations
        count_stmt = select(func.count(Conversation.id)).where(
            Conversation.user_id == userId,
            Conversation.deleted_at.is_(None)  # Exclude soft-deleted
        )
        count_result = await self.db.execute(count_stmt)
        total_count = count_result.scalar()
        
        # Get conversations with pagination
        stmt = select(Conversation).where(
            Conversation.user_id == userId,
            Conversation.deleted_at.is_(None)
        ).order_by(
            desc(Conversation.started_at)
        ).limit(limit).offset(offset)
        
        result = await self.db.execute(stmt)
        conversations = result.scalars().all()
        
        logger.info(f"üìã Listed {len(conversations)} conversations (total: {total_count})")
        return list(conversations), total_count
    
    
    async def getConversationDetail(
        self,
        conversationId: UUID,
        userId: UUID
    ) -> Conversation:
        """
        L·∫•y chi ti·∫øt conversation v·ªõi t·∫•t c·∫£ messages
        
        Args:
            conversationId: Conversation ID
            userId: User ID (ƒë·ªÉ verify ownership)
        
        Returns:
            Conversation object v·ªõi messages loaded
        
        Raises:
            NotFoundException: N·∫øu conversation kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng thu·ªôc user
        """
        stmt = select(Conversation).where(
            Conversation.id == conversationId,
            Conversation.user_id == userId,
            Conversation.deleted_at.is_(None)
        )
        result = await self.db.execute(stmt)
        conversation = result.scalar_one_or_none()
        
        if not conversation:
            raise NotFoundException(f"Conversation {conversationId} not found")
        
        logger.info(f"üìñ Loaded conversation detail: {conversationId}")
        return conversation
    
    
    async def deleteConversation(
        self,
        conversationId: UUID,
        userId: UUID
    ) -> bool:
        """
        X√≥a conversation (soft delete)
        
        Args:
            conversationId: Conversation ID
            userId: User ID (ƒë·ªÉ verify ownership)
        
        Returns:
            bool: True n·∫øu x√≥a th√†nh c√¥ng
        
        Raises:
            NotFoundException: N·∫øu conversation kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng thu·ªôc user
        """
        stmt = select(Conversation).where(
            Conversation.id == conversationId,
            Conversation.user_id == userId,
            Conversation.deleted_at.is_(None)
        )
        result = await self.db.execute(stmt)
        conversation = result.scalar_one_or_none()
        
        if not conversation:
            raise NotFoundException(f"Conversation {conversationId} not found")
        
        # Soft delete
        conversation.deleted_at = datetime.utcnow()
        await self.db.commit()
        
        # Invalidate cache
        cache_key = str(conversationId)
        if cache_key in _CONVERSATION_CACHE:
            del _CONVERSATION_CACHE[cache_key]
        
        logger.info(f"üóëÔ∏è Deleted conversation: {conversationId}")
        return True
    
    
    async def updateConversation(
        self,
        conversationId: UUID,
        userId: UUID,
        title: Optional[str] = None,
        status: Optional[str] = None
    ) -> Conversation:
        """
        C·∫≠p nh·∫≠t conversation metadata
        
        Args:
            conversationId: Conversation ID
            userId: User ID (ƒë·ªÉ verify ownership)
            title: New title (optional)
            status: New status (optional): 'active', 'ended', 'archived'
        
        Returns:
            Updated Conversation object
        
        Raises:
            NotFoundException: N·∫øu conversation kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng thu·ªôc user
        """
        stmt = select(Conversation).where(
            Conversation.id == conversationId,
            Conversation.user_id == userId,
            Conversation.deleted_at.is_(None)
        )
        result = await self.db.execute(stmt)
        conversation = result.scalar_one_or_none()
        
        if not conversation:
            raise NotFoundException(f"Conversation {conversationId} not found")
        
        # Update fields
        if title is not None:
            conversation.title = title
        if status is not None:
            conversation.status = status
            if status == 'ended':
                conversation.ended_at = datetime.utcnow()
        
        conversation.updated_at = datetime.utcnow()
        await self.db.commit()
        
        # Invalidate cache
        cache_key = str(conversationId)
        if cache_key in _CONVERSATION_CACHE:
            _CONVERSATION_CACHE[cache_key] = (conversation, datetime.utcnow())
        
        logger.info(f"‚úèÔ∏è Updated conversation: {conversationId}")
        return conversation
